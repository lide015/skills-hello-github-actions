#!/bin/bash

# ========================================
# AIè‡ªå‹•åŒ–æŽ¥æ¡ˆå¹³å° - å®Œæ•´éƒ¨ç½²è…³æœ¬
# ========================================

echo "ðŸš€ é–‹å§‹å»ºç½®AIæŽ¥æ¡ˆå¹³å°..."

# ç¬¬ä¸€æ®µï¼šå»ºç½®å‘½ä»¤ (Infrastructure Setup)
setup_infrastructure() {
    echo "ðŸ“¦ ç¬¬ä¸€éšŽæ®µï¼šåŸºç¤Žæž¶æ§‹å»ºç½®"
    
    # Dockerç’°å¢ƒæº–å‚™
    echo "å®‰è£Dockerç’°å¢ƒ..."
    sudo apt update
    sudo apt install -y docker.io docker-compose
    sudo systemctl start docker
    sudo systemctl enable docker
    
    # å»ºç«‹å°ˆæ¡ˆçµæ§‹
    echo "å»ºç«‹å°ˆæ¡ˆç›®éŒ„çµæ§‹..."
    mkdir -p ai_platform/{backend,frontend,ai_service,database,nginx,scripts}
    mkdir -p ai_platform/backend/{api,models,services,utils}
    mkdir -p ai_platform/frontend/{src,public,components}
    mkdir -p ai_platform/ai_service/{matching,evaluation,automation}
    
    # å»ºç«‹Dockerç¶²è·¯
    docker network create ai_platform_network
    
    echo "âœ… åŸºç¤Žæž¶æ§‹å»ºç½®å®Œæˆ"
}

# ç¬¬äºŒæ®µï¼šè¼¸å…¥ç›®éŒ„ (Directory Configuration)
setup_directories() {
    echo "ðŸ“ ç¬¬äºŒéšŽæ®µï¼šç›®éŒ„é…ç½®èˆ‡ç’°å¢ƒè¨­å®š"
    
    # é€²å…¥å°ˆæ¡ˆæ ¹ç›®éŒ„
    cd ai_platform
    
    # å»ºç«‹ç’°å¢ƒé…ç½®æ–‡ä»¶
    cat > .env << EOF
# è³‡æ–™åº«é…ç½®
DB_HOST=localhost
DB_PORT=5432
DB_NAME=ai_platform
DB_USER=platform_user
DB_PASSWORD=secure_password_2024

# Redisé…ç½®
REDIS_HOST=localhost
REDIS_PORT=6379

# AIæœå‹™é…ç½®
AI_MODEL_PATH=./models
OPENAI_API_KEY=your_openai_key_here
MATCHING_ALGORITHM=enhanced_ml

# å¹³å°é…ç½®
PLATFORM_NAME=AIæŽ¥æ¡ˆå¹³å°
COMMISSION_RATE=0.15
PAYMENT_GATEWAY=ecpay

# å®‰å…¨è¨­å®š
JWT_SECRET=your_jwt_secret_here
SESSION_SECRET=your_session_secret_here

# ç¬¬ä¸‰æ–¹æœå‹™
SMTP_HOST=smtp.gmail.com
SMTP_USER=your_email@gmail.com
SMTP_PASS=your_app_password
EOF

    # å»ºç«‹Docker Composeé…ç½®
    cat > docker-compose.yml << 'EOF'
version: '3.8'

services:
  # PostgreSQLè³‡æ–™åº«
  postgres:
    image: postgres:15
    container_name: ai_platform_db
    environment:
      POSTGRES_DB: ${DB_NAME}
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    networks:
      - ai_platform_network

  # Redisç·©å­˜
  redis:
    image: redis:7-alpine
    container_name: ai_platform_redis
    ports:
      - "6379:6379"
    networks:
      - ai_platform_network

  # å¾Œç«¯APIæœå‹™
  backend:
    build: ./backend
    container_name: ai_platform_backend
    environment:
      - NODE_ENV=production
    ports:
      - "3000:3000"
    depends_on:
      - postgres
      - redis
    networks:
      - ai_platform_network
    volumes:
      - ./uploads:/app/uploads

  # AIåŒ¹é…æœå‹™
  ai_service:
    build: ./ai_service
    container_name: ai_platform_ai
    environment:
      - PYTHON_ENV=production
    ports:
      - "5000:5000"
    depends_on:
      - redis
    networks:
      - ai_platform_network
    volumes:
      - ./models:/app/models

  # å‰ç«¯æ‡‰ç”¨
  frontend:
    build: ./frontend
    container_name: ai_platform_frontend
    ports:
      - "80:80"
    depends_on:
      - backend
    networks:
      - ai_platform_network

  # Nginxåå‘ä»£ç†
  nginx:
    image: nginx:alpine
    container_name: ai_platform_nginx
    ports:
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - frontend
      - backend
    networks:
      - ai_platform_network

volumes:
  postgres_data:

networks:
  ai_platform_network:
    driver: bridge
EOF

    echo "âœ… ç›®éŒ„é…ç½®å®Œæˆ"
}

# ç¬¬ä¸‰æ®µï¼šå®‰è£å‘½ä»¤ (Application Installation)
install_applications() {
    echo "ðŸ”§ ç¬¬ä¸‰éšŽæ®µï¼šæ‡‰ç”¨ç¨‹å¼å®‰è£èˆ‡é…ç½®"
    
    # å»ºç«‹è³‡æ–™åº«åˆå§‹åŒ–è…³æœ¬
    cat > database/init.sql << 'EOF'
-- AIæŽ¥æ¡ˆå¹³å°è³‡æ–™åº«çµæ§‹

-- ç”¨æˆ¶è¡¨
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    user_type VARCHAR(20) NOT NULL, -- 'client' or 'freelancer'
    profile_data JSONB,
    skill_tags TEXT[],
    rating DECIMAL(3,2) DEFAULT 0.00,
    total_earnings DECIMAL(10,2) DEFAULT 0.00,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ä»»å‹™è¡¨
CREATE TABLE tasks (
    id SERIAL PRIMARY KEY,
    client_id INTEGER REFERENCES users(id),
    title VARCHAR(200) NOT NULL,
    description TEXT,
    requirements JSONB,
    budget_min DECIMAL(10,2),
    budget_max DECIMAL(10,2),
    deadline TIMESTAMP,
    status VARCHAR(20) DEFAULT 'open', -- 'open', 'in_progress', 'completed', 'cancelled'
    ai_complexity_score INTEGER,
    required_skills TEXT[],
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ç«¶æ¨™è¡¨
CREATE TABLE bids (
    id SERIAL PRIMARY KEY,
    task_id INTEGER REFERENCES tasks(id),
    freelancer_id INTEGER REFERENCES users(id),
    bid_amount DECIMAL(10,2),
    proposal TEXT,
    estimated_hours INTEGER,
    ai_match_score DECIMAL(5,4),
    status VARCHAR(20) DEFAULT 'pending',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- äº¤æ˜“è¨˜éŒ„è¡¨
CREATE TABLE transactions (
    id SERIAL PRIMARY KEY,
    task_id INTEGER REFERENCES tasks(id),
    client_id INTEGER REFERENCES users(id),
    freelancer_id INTEGER REFERENCES users(id),
    amount DECIMAL(10,2),
    commission DECIMAL(10,2),
    status VARCHAR(20) DEFAULT 'pending',
    payment_method VARCHAR(50),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- AIåŒ¹é…è¨˜éŒ„è¡¨
CREATE TABLE ai_matches (
    id SERIAL PRIMARY KEY,
    task_id INTEGER REFERENCES tasks(id),
    freelancer_id INTEGER REFERENCES users(id),
    match_score DECIMAL(5,4),
    match_factors JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- å»ºç«‹ç´¢å¼•
CREATE INDEX idx_users_type ON users(user_type);
CREATE INDEX idx_tasks_status ON tasks(status);
CREATE INDEX idx_bids_task ON bids(task_id);
CREATE INDEX idx_transactions_status ON transactions(status);
EOF

    # å»ºç«‹å¾Œç«¯API Dockerfile
    cat > backend/Dockerfile << 'EOF'
FROM node:18-alpine

WORKDIR /app

COPY package*.json ./
RUN npm ci --only=production

COPY . .

EXPOSE 3000

CMD ["node", "server.js"]
EOF

    # å»ºç«‹AIæœå‹™Dockerfile
    cat > ai_service/Dockerfile << 'EOF'
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 5000

CMD ["python", "app.py"]
EOF

    # å»ºç«‹å‰ç«¯Dockerfile
    cat > frontend/Dockerfile << 'EOF'
FROM node:18-alpine as builder

WORKDIR /app
COPY package*.json ./
RUN npm ci

COPY . .
RUN npm run build

FROM nginx:alpine
COPY --from=builder /app/dist /usr/share/nginx/html
COPY nginx.conf /etc/nginx/nginx.conf

EXPOSE 80
EOF

    # å•Ÿå‹•æœå‹™
    echo "ðŸš€ å•Ÿå‹•æ‰€æœ‰æœå‹™..."
    docker-compose up -d

    # ç­‰å¾…æœå‹™å•Ÿå‹•
    echo "â³ ç­‰å¾…æœå‹™åˆå§‹åŒ–..."
    sleep 30

    # æª¢æŸ¥æœå‹™ç‹€æ…‹
    echo "ðŸ” æª¢æŸ¥æœå‹™ç‹€æ…‹..."
    docker-compose ps

    echo "âœ… æ‰€æœ‰æœå‹™å®‰è£å®Œæˆï¼"
}

# é¡å¤–çš„ç®¡ç†è…³æœ¬
create_management_scripts() {
    echo "ðŸ“‹ å»ºç«‹ç®¡ç†è…³æœ¬..."
    
    # å»ºç«‹AIæ¨¡åž‹è¨“ç·´è…³æœ¬
    cat > scripts/train_matching_model.py << 'EOF'
#!/usr/bin/env python3
"""
AIé…å°æ¨¡åž‹è¨“ç·´è…³æœ¬
åŸºæ–¼æ­·å²é…å°æˆåŠŸçŽ‡è¨“ç·´æ©Ÿå™¨å­¸ç¿’æ¨¡åž‹
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import joblib

def train_matching_model():
    """è¨“ç·´AIé…å°æ¨¡åž‹"""
    print("ðŸ¤– é–‹å§‹è¨“ç·´AIé…å°æ¨¡åž‹...")
    
    # é€™è£¡æœƒå¾žè³‡æ–™åº«è¼‰å…¥æ­·å²è³‡æ–™
    # ç‰¹å¾µåŒ…æ‹¬ï¼šæŠ€èƒ½åŒ¹é…åº¦ã€åƒ¹æ ¼åˆç†æ€§ã€å®Œæˆæ™‚é–“é ä¼°ç­‰
    
    # æ¨¡æ“¬æ•¸æ“šï¼ˆå¯¦éš›ä½¿ç”¨æ™‚å¾žè³‡æ–™åº«ç²å–ï¼‰
    features = ['skill_match', 'price_ratio', 'time_estimation', 'rating_diff']
    
    # è¨“ç·´æ¨¡åž‹
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    
    # å„²å­˜æ¨¡åž‹
    joblib.dump(model, '../models/matching_model.pkl')
    print("âœ… AIé…å°æ¨¡åž‹è¨“ç·´å®Œæˆ")

if __name__ == "__main__":
    train_matching_model()
EOF

    # å»ºç«‹ç³»çµ±ç›£æŽ§è…³æœ¬
    cat > scripts/monitor_system.sh << 'EOF'
#!/bin/bash

echo "ðŸ“Š AIæŽ¥æ¡ˆå¹³å°ç³»çµ±ç›£æŽ§å ±å‘Š"
echo "=================================="

# æª¢æŸ¥Dockerå®¹å™¨ç‹€æ…‹
echo "ðŸ³ Dockerå®¹å™¨ç‹€æ…‹ï¼š"
docker-compose ps

# æª¢æŸ¥è³‡æ–™åº«é€£æŽ¥
echo -e "\nðŸ’¾ è³‡æ–™åº«ç‹€æ…‹ï¼š"
docker exec ai_platform_db pg_isready

# æª¢æŸ¥Redisç‹€æ…‹  
echo -e "\nðŸ”„ Redisç‹€æ…‹ï¼š"
docker exec ai_platform_redis redis-cli ping

# æª¢æŸ¥APIå¥åº·ç‹€æ…‹
echo -e "\nðŸ”Œ APIå¥åº·æª¢æŸ¥ï¼š"
curl -s http://localhost:3000/health || echo "APIç„¡æ³•è¨ªå•"

# æª¢æŸ¥AIæœå‹™ç‹€æ…‹
echo -e "\nðŸ¤– AIæœå‹™ç‹€æ…‹ï¼š"
curl -s http://localhost:5000/status || echo "AIæœå‹™ç„¡æ³•è¨ªå•"

echo -e "\nâœ… ç›£æŽ§å ±å‘Šå®Œæˆ"
EOF

    chmod +x scripts/*.sh scripts/*.py
    echo "âœ… ç®¡ç†è…³æœ¬å»ºç«‹å®Œæˆ"
}

# ä¸»åŸ·è¡Œæµç¨‹
main() {
    echo "ðŸŽ¯ AIæŽ¥æ¡ˆå¹³å°è‡ªå‹•åŒ–éƒ¨ç½²é–‹å§‹"
    
    setup_infrastructure
    setup_directories  
    install_applications
    create_management_scripts
    
    echo ""
    echo "ðŸŽ‰ éƒ¨ç½²å®Œæˆï¼"
    echo "=================================="
    echo "ðŸ“± å‰ç«¯ç¶²å€: http://localhost"
    echo "ðŸ”Œ APIç«¯é»ž: http://localhost:3000"
    echo "ðŸ¤– AIæœå‹™: http://localhost:5000"
    echo "ðŸ’¾ è³‡æ–™åº«: localhost:5432"
    echo ""
    echo "ðŸ› ï¸ ç®¡ç†å‘½ä»¤ï¼š"
    echo "  ç›£æŽ§ç³»çµ±: ./scripts/monitor_system.sh"
    echo "  è¨“ç·´AI: python scripts/train_matching_model.py"
    echo "  é‡å•Ÿæœå‹™: docker-compose restart"
    echo ""
    echo "ðŸ“‹ ä¸‹ä¸€æ­¥å»ºè­°ï¼š"
    echo "  1. è¨­å®šSSLæ†‘è­‰"
    echo "  2. é…ç½®æ”¯ä»˜ç¶²é—œ"
    echo "  3. è¨“ç·´AIé…å°æ¨¡åž‹"
    echo "  4. é€²è¡Œä½¿ç”¨è€…æ¸¬è©¦"
}

# åŸ·è¡Œä¸»å‡½æ•¸
main "$@"
